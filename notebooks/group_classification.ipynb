{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "# import pathpy as pp\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from datetime import timedelta\n",
    "import random\n",
    "from more_itertools import distinct_combinations\n",
    "\n",
    "import pygraphviz\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\"copenhagen_interactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"./data\")\n",
    "OUTPUT_FOLDER = Path(\"./output\")\n",
    "TEST_FOLDER = Path(\"./tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_FOLDER / \"copenhagen_interactions_distance.csv\", parse_dates=[\"datetime\"])\n",
    "thresh = 90\n",
    "days = [snapshot for _, snapshot in df.resample(\"D\", on=\"datetime\")]\n",
    "five_minutes = [[snapshot for _, snapshot in d.resample(\"5T\", on=\"datetime\")] for d in days]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use this to visualize a graph. the param `labels` is for labels on the edges. by default there are labels on the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph(G, labels=False):\n",
    "    plt.figure(1, figsize=(4,4))\n",
    "    if labels == True:\n",
    "        pos = nx.spring_layout(G, k=1, weight='distance')\n",
    "    else:\n",
    "        pos = graphviz_layout(G, prog=\"neato\")\n",
    "    nx.draw(G, pos, node_size=40, vmin=0.0, vmax=1.0, with_labels=True)\n",
    "    if labels:\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels={t[:2]: t[2][\"distance\"] for t in G.edges.data()})\n",
    "    plt.show()\n",
    "#     plt.savefig(f\"{'-'.join(list(map(str,shortest_path)))}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. take each connected component in each timestamp with over two nodes (i.e. group interactions)\n",
    "2. remove nodes that are completely disconnected from component when threshold is in place\n",
    "3. remove edges above threshold\n",
    "4. find the complementory graph\n",
    "5. find the length of the shortest path between each two nodes from complementory graph in original graph, and append it as an edge to the original graph\n",
    "6. add the now full graph to a list of meetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetings = []\n",
    "for day in range(dataset.period):\n",
    "    print(day)\n",
    "    for i, fm in enumerate(five_minutes[day]):\n",
    "        G = nx.from_pandas_edgelist(fm, target=\"destination\", edge_attr=\"distance\")\n",
    "        timestamp = fm[\"datetime\"].iloc[0]\n",
    "        subgraphs = [G.subgraph(c).copy() for c in nx.connected_components(G) if len(c) > 2]\n",
    "        # subgraphs = list of any connected component with over 2 nodes in current timestamp\n",
    "        for SG in subgraphs:\n",
    "            # G_relevant_nodes = graph consisting of the nodes of all components that are still connected\n",
    "            #     if edges are filtered to be under threshold\n",
    "            G_relevant_nodes = G.subgraph(sum([[u,v] for u,v,d in SG.edges(data=True) if d['distance'] < thresh], [])).copy()\n",
    "            # if the components left are still a group meeting => add hops to the mix\n",
    "            if len(G_relevant_nodes) > 2:\n",
    "                # G_sub = a subgraph of G_relevant_nodes by filtering out edges with distance above threshold \n",
    "                G_sub = G_relevant_nodes.edge_subgraph(\n",
    "                    [(u,v) for u,v,d in G_relevant_nodes.edges(data=True) if d['distance'] < thresh]\n",
    "                ).copy()\n",
    "                # H = complementory graph, all the moissing edges to form a complete graph\n",
    "                H = nx.complement(G_sub)\n",
    "                for t in H.edges(): \n",
    "                    # add an edge + attr or only attr if edge already exists with the amount of hops needed to \"create\" this path \n",
    "                    SG.add_edge(*t, **{\"hops\": len(nx.shortest_path(SG, *t))})\n",
    "#                 meetings.append(nx.to_pandas_edgelist(SG).assign(**{\"meeting_number\": meeting_n, \"timestamp\": timestamp}))\n",
    "                meetings.append([SG, timestamp])\n",
    "#         union = nx.union_all(timestamp_graphs)\n",
    "\n",
    "cdf = pd.DataFrame(meetings, columns=[\"meetings\", \"timestamp\"])\n",
    "# cdf = pd.concat(meetings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a dataframe out of all meetings, grouping by timediff, so to create continuous meetings over timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_dict = cdf.to_dict()\n",
    "cdf_exploded = (pd.concat(\n",
    "    [nx.to_pandas_edgelist(v).assign(**{\"timestamp\": cdf_dict[\"timestamp\"][k]}) for k, v in cdf_dict[\"meetings\"].items()]\n",
    ").rename(columns={\"target\": \"destination\"}))\n",
    "\n",
    "cdf_exploded[\"meeting_nodes\"] = cdf_exploded[[\"source\", \"destination\"]].apply(lambda x: tuple(sorted(x)), axis=1)\n",
    "cdf_exploded = cdf_exploded.sort_values([\"meeting_nodes\", \"timestamp\"]).reset_index(drop=True)\n",
    "cdf_exploded[\"meeting_id\"] = (cdf_exploded[\"timestamp\"].diff() !=  pd.Timedelta('5m')).cumsum()\n",
    "\n",
    "cdf_exploded = (cdf_exploded.groupby([\"meeting_id\",\"meeting_nodes\"])\n",
    "            .agg(**{\n",
    "                \"duration\": pd.NamedAgg(column='timestamp', aggfunc=lambda x: x.count() * 5), \n",
    "                \"datetime\": pd.NamedAgg(column='timestamp', aggfunc='min'),\n",
    "                \"hops\":  pd.NamedAgg(column='hops', aggfunc='mean'),\n",
    "                \"distance\": pd.NamedAgg(column='distance', aggfunc='mean')\n",
    "            }).reset_index()\n",
    "           )\n",
    "cdf_exploded[[\"source\", \"destination\"]] = pd.DataFrame(cdf_exploded[\"meeting_nodes\"].tolist())\n",
    "cdf_exploded = cdf_exploded.drop(columns=[\"meeting_nodes\", \"meeting_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get all one-on-one meetings from original csv, aggregate them by timediff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_time_diff(df):\n",
    "    groups = (df.sort_values([\"source\",\"destination\"])[\"datetime\"].diff() !=  pd.Timedelta('5m')).cumsum()\n",
    "    df[\"groups\"] = groups\n",
    "    return (df.groupby([\"source\",\"destination\", \"groups\"])\n",
    "            .agg(**{\n",
    "                \"duration\": pd.NamedAgg(column='datetime', aggfunc=lambda x: x.count() * 5), \n",
    "                \"datetime\": pd.NamedAgg(column='datetime', aggfunc='min'),\n",
    "                \"distance\": pd.NamedAgg(column='distance', aggfunc='mean')\n",
    "            })\n",
    "            .reset_index()\n",
    "            .drop(columns=[\"groups\"])\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time new_df = df.groupby([\"source\", \"destination\"]).apply(group_by_time_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = cdf_exploded.append(new_df).drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"copenhagen_hops.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = venn2([set(final.index[~final[\"distance\"].isna()]), set(final.index[~final[\"hops\"].isna()])], (\"distance\", \"hops\"))\n",
    "ax.figsize = (8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = alt.Chart(final[(final[\"distance\"]>=80) & (final[\"hops\"]<5)]).mark_rect().encode(\n",
    "    alt.X('hops:Q', bin=alt.Bin(maxbins=6)),\n",
    "    alt.Y('distance:Q', bin=alt.Bin(maxbins=20)),\n",
    "    alt.Color('count()', scale=alt.Scale(scheme='greenblue')),\n",
    ")\n",
    "chart.save(\n",
    "    str(OUTPUT_FOLDER / \"hops_vs_distance.html\"), format=\"html\"\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leftovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meetings_df = cdf.copy()\n",
    "# meetings_df[\"meeting_nodes\"] = meetings_df[\"meetings\"].apply(lambda x: tuple(sorted(x.nodes)))\n",
    "# meetings_df = meetings_df.sort_values([\"meeting_nodes\", \"timestamp\"]).reset_index(drop=True)\n",
    "# meetings_df[\"meeting_id\"] = (meetings_df[\"timestamp\"].diff() !=  pd.Timedelta('5m')).cumsum()\n",
    "\n",
    "# meetings_df = (meetings_df.groupby([\"meeting_id\", \"meeting_nodes\"])\n",
    "#             .agg(**{\n",
    "#                 \"duration\": pd.NamedAgg(column='timestamp', aggfunc=lambda x: x.count() * 5), \n",
    "#                 \"datetime\": pd.NamedAgg(column='timestamp', aggfunc='min')\n",
    "#             }).reset_index()\n",
    "#            )\n",
    "# meetings_df[\"participants\"] = meetings_df[\"meeting_nodes\"].str.len()\n",
    "# # meetings_index = cdf[[\"group\", \"meetings\"]].drop_duplicates(\"meetings\")\n",
    "# meetings_df[\"meeting_nodes\"] = meetings_df[\"meeting_nodes\"].apply(lambda x: list(distinct_combinations(x, r=2)))\n",
    "# meetings_df = meetings_df.explode(\"meeting_nodes\").reset_index(drop=True)\n",
    "# meetings_df[[\"source\", \"destination\"]] = pd.DataFrame(meetings_df[\"meeting_nodes\"].tolist())\n",
    "# meetings_df = meetings_df.set_index([\"datetime\", \"meeting_nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_full(G):\n",
    "    degrees = [x[1] for x in list(G.degree)]\n",
    "    return True if len(set(degrees))==1 and degrees[0] == len(G)-1 else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infection in meetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days = []\n",
    "for day in range(dataset.period):\n",
    "    groups = []\n",
    "    for i, fm in enumerate(five_minutes[day]):\n",
    "        G = from_pandas_edgelist(fm, target=\"destination\")\n",
    "        groups += list(set(sum([x for x in list(find_cliques(G)) if len(x) > 2], [])))\n",
    "    meetings = (pd.DataFrame.from_dict(\n",
    "        {\"meeting_duration\": {k: v*5 for k, v in dict(Counter(groups)).items()}}\n",
    "    ).join(days[day][[\"source\", \"destination\"]]\n",
    "           .stack()\n",
    "           .value_counts()\n",
    "           .rename(\"all_interactions\")*5).assign(\n",
    "        percent=lambda x:x[\"meeting_duration\"] / x[\"all_interactions\"], \n",
    "                        infection_date=dataset.start_date + timedelta(days=day)))\n",
    "    all_days.append(meetings)\n",
    "percents = pd.concat(all_days).reset_index().rename(columns={\"index\": \"id\"}).set_index([\"infection_date\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_pickle(OUTPUT_FOLDER / \"9427637205343771_df.pkl\").reset_index().set_index([\"infection_date\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output.join(percents, how=\"left\")[\"percent\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trig and triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_angle(a, b, c):\n",
    "    return np.arccos((b**2 + c**2 - a**2) / (2*b*c)) * 180/np.pi\n",
    "\n",
    "import math \n",
    "\n",
    "def find_side(a, b, C):\n",
    "    return math.sqrt(a**2 + b**2 - 2*b*a*np.cos(C))\n",
    "\n",
    "find_side(90, 78, 62.697)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## pathpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(split):\n",
    "    df[\"time\"] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.concat(split[:10])[[\"source\", \"destination\", \"time\"]]\n",
    "tn = pp.io.from_dataframe(dff, directed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = pp.Network(temporal=True)\n",
    "for i in range(288):\n",
    "    for _, s, d, t in split[i][[\"source\", \"destination\", \"datetime\"]].itertuples():\n",
    "        tn.add_edge(pp.Edge(pp.Node(s), pp.Node(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {\"width\": 1500, \"height\": 600, \"label_opacity\": 0}\n",
    "#          , \"ms_per_frame\": 500}\n",
    "pp.visualisation.export_html(tn, './temporal_network.html', **style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSSI max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict({\"amount\":{i:len(df[df[\"distance\"]<i]) for i in range(df[\"distance\"].max()+1)}}).plot(logy=True)\n",
    "# df.groupby(\"distance\")[\"source\"].count().plot.bar(figsize=(16,8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ossi",
   "language": "python",
   "name": "ossi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
